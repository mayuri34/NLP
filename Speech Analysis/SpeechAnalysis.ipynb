{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output for speaker LEHRER:\n",
      "\n",
      "Porter Stemmer(10 most frequent words):\n",
      "[('governor', 23), ('two', 23), ('minut', 22), ('presid', 21), ('go', 21), ('right', 20), ('let', 18), ('mr', 15), ('first', 14), ('govern', 14)]\n",
      "\n",
      "Snowball Stemmer(10 most frequent words):\n",
      "[('governor', 23), ('two', 23), ('minut', 22), ('presid', 21), ('go', 21), ('right', 20), ('let', 18), ('mr', 15), ('first', 14), ('govern', 14)]\n",
      "\n",
      "Lancaster Stemmer(10 most frequent words):\n",
      "[('govern', 37), ('presid', 25), ('two', 23), ('minut', 22), ('right', 20), ('let', 18), ('mr', 15), ('first', 14), ('go', 13), ('seg', 12)]\n",
      "\n",
      "10 most frequent positive words: \n",
      "[('right', 20), ('well', 7), ('support', 4), ('candid', 3), ('great', 1), ('even', 1), ('open', 1), ('good', 1), ('cheer', 1)]\n",
      "\n",
      "Output for speaker OBAMA:\n",
      "\n",
      "Porter Stemmer(10 most frequent words):\n",
      "[('make', 57), ('governor', 50), ('go', 49), ('romney', 44), ('weve', 35), ('got', 34), ('tax', 34), ('that', 34), ('say', 30), ('know', 29)]\n",
      "\n",
      "Snowball Stemmer(10 most frequent words):\n",
      "[('make', 57), ('governor', 50), ('go', 49), ('romney', 44), ('weve', 35), ('got', 34), ('tax', 34), ('that', 34), ('say', 30), ('know', 29)]\n",
      "\n",
      "Lancaster Stemmer(10 most frequent words):\n",
      "[('govern', 60), ('mak', 57), ('romney', 44), ('going', 38), ('wev', 35), ('got', 35), ('tax', 34), ('that', 34), ('say', 30), ('know', 29)]\n",
      "\n",
      "10 most frequent positive words: \n",
      "[('well', 25), ('sure', 22), ('help', 20), ('right', 12), ('reason', 11), ('top', 9), ('deal', 8), ('great', 8), ('reform', 7), ('basic', 7)]\n",
      "\n",
      "Output for speaker ROMNEY:\n",
      "\n",
      "Porter Stemmer(10 most frequent words):\n",
      "[('peopl', 72), ('tax', 69), ('get', 69), ('go', 67), ('that', 46), ('presid', 44), ('plan', 42), ('cut', 40), ('one', 34), ('said', 33)]\n",
      "\n",
      "Snowball Stemmer(10 most frequent words):\n",
      "[('peopl', 72), ('tax', 69), ('get', 69), ('go', 67), ('that', 46), ('presid', 44), ('plan', 42), ('cut', 40), ('one', 34), ('said', 33)]\n",
      "\n",
      "Lancaster Stemmer(10 most frequent words):\n",
      "[('peopl', 72), ('tax', 70), ('get', 69), ('going', 52), ('presid', 47), ('that', 46), ('plan', 42), ('cut', 40), ('govern', 36), ('stat', 35)]\n",
      "\n",
      "10 most frequent positive words: \n",
      "[('well', 27), ('right', 25), ('kind', 14), ('sure', 11), ('better', 10), ('good', 8), ('help', 7), ('free', 6), ('great', 6), ('reason', 6)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "porterstemmer = PorterStemmer()\n",
    "\n",
    "def debate_results():\n",
    "    file = open('debate.txt','r')\n",
    "    debate_corpus = file.read()\n",
    "    text = ' '.join(debate_corpus.splitlines())\n",
    "    \n",
    "    #stripping text of crosstalk and audience background noise\n",
    "    without_crosstalk = text.replace('(CROSSTALK)','')\n",
    "    refined_statement = without_crosstalk.replace('(inaudible)','')\n",
    "    \n",
    "    #regex patterns for extracting conversations of individual speakers\n",
    "    lehrer_re = re.compile('(?<=LEHRER:).*?((?=OBAMA:)|(?=ROMNEY:)|(?=LEHRER:))')\n",
    "    obama_re = re.compile('(?<=OBAMA:).*?((?=OBAMA:)|(?=ROMNEY:)|(?=LEHRER:))')\n",
    "    romney_re = re.compile('(?<=ROMNEY:).*?((?=OBAMA:)|(?=ROMNEY:)|(?=LEHRER:))')\n",
    "        \n",
    "    lehrer_text = re.finditer(lehrer_re, refined_statement)    \n",
    "    stem_output(lehrer_text, 'LEHRER')\n",
    "    \n",
    "    obama_text = re.finditer(obama_re, refined_statement)\n",
    "    stem_output(obama_text, 'OBAMA')\n",
    "    \n",
    "    romney_text = re.finditer(romney_re, refined_statement)\n",
    "    stem_output(romney_text, 'ROMNEY')\n",
    "    \n",
    "def stem_output(text, speaker):\n",
    "    \n",
    "    #code for removing punctuation, capitalization and stop words\n",
    "    statement = ''\n",
    "    for t in text:\n",
    "        statement += t.group()    \n",
    "    keys = str.maketrans({key: None for key in string.punctuation})\n",
    "    out = statement.translate(keys) \n",
    "    lower_output = out.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    #tokenizing the text\n",
    "    tokens = word_tokenize(lower_output)\n",
    "    refined_sentence = [t for t in tokens if t not in stop_words]\n",
    "    \n",
    "    print('\\nOutput for speaker '+ speaker +':')\n",
    "    \n",
    "    #Porter Stemmer\n",
    "    porter_stemmed  = [porterstemmer.stem(s) for s in refined_sentence]\n",
    "    output_frequency(porter_stemmed, 'Porter Stemmer')\n",
    "    \n",
    "    #Snowball Stemmer\n",
    "    snowball_stemmed = [SnowballStemmer(\"english\").stem(ps) for ps in refined_sentence]\n",
    "    output_frequency(snowball_stemmed, 'Snowball Stemmer')\n",
    "    \n",
    "    #Lancaster Stemmer\n",
    "    lancaster_stemmed = [LancasterStemmer().stem(ss) for ss in refined_sentence]\n",
    "    output_frequency(lancaster_stemmed, 'Lancaster Stemmer')\n",
    "    \n",
    "    positive_word_frequency(porter_stemmed)\n",
    "    \n",
    "    \n",
    "def output_frequency(text, stemmer_used):\n",
    "    \n",
    "    #Code for calculating frequency of words\n",
    "    counter = Counter(text)\n",
    "    print('\\n' + stemmer_used + '(10 most frequent words):')\n",
    "    print(counter.most_common(10))\n",
    "    \n",
    "def positive_word_frequency(text):\n",
    "    \n",
    "    #Logic of extracting common words from speech and \n",
    "    #positive dictionary and calculating their frequency\n",
    "    \n",
    "    file = open('positive.txt','r')\n",
    "    dictionary = file.read()\n",
    "    \n",
    "    stemmed_dictionary = porterstemmer.stem(dictionary)\n",
    "    counter = collections.Counter(text) \n",
    "    common = set(text).intersection( set(stemmed_dictionary.split('\\n')) )\n",
    "    positive_counter = Counter()\n",
    "    \n",
    "    for c in common:\n",
    "        positive_counter[c] = counter[c]\n",
    "        \n",
    "    print('\\n10 most frequent positive words: ')\n",
    "    print(positive_counter.most_common(10))\n",
    "     \n",
    "if __name__ == '__main__':\n",
    "    debate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hart@vmd.cso.uiuc.edu', 'hart@uiucvmd', '72600.2026@compuserve.com', 'Martin.Ward@uk.ac.durham', 'ccx074@coventry.ac.uk']\n"
     ]
    }
   ],
   "source": [
    "#Regular expression for extracting email pairs of given input text \n",
    "str = \"\"\"\n",
    "\n",
    "        ... austen-emma.txt:hart@vmd.cso.uiuc.edu (internet) hart@uiucvmd (bitnet)\n",
    "\n",
    "       ... austen-emma.txt:Internet (72600.2026@compuserve.com); TEL: (212-254-5093) .\n",
    "\n",
    "      .. austen-persuasion.txt:Editing by Martin Ward (Martin.Ward@uk.ac.durham)\n",
    "\n",
    "      ... blake-songs.txt:Prepared by David Price, email ccx074@coventry.ac.uk... \"\"\"\n",
    "\n",
    "output = re.findall(r'[\\w.]+@[\\w.]+\\b', str, flags=0)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What differences do you observe between the different stemmer outputs?\n",
    "\n",
    "Even though Snowball stemmer is considered as an improvement over Porter stemmer, at least for the above output both stemmers give identical results, whereas Lancaster stemmer has a few noticable differences. For example, in Lehrer's speech results we can see that Porter and Snowball have stemmed a word as 'governor'. But Lancaster has aggressively stemmed it even further to 'govern'. This has increased the number of matches since Lancaster's output also included words like 'government' and not just 'governor'. Similarly, words like 'president' and 'presidential' both got stemmed to 'presid' by Lancaster Stemmer (unlike Porter or Snowball). Hence, Lancaster stemmer is more aggressive in its stemming and produces more matches compared to other two stemmers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
